## AI Act {#AI-Act .chapter .small .term}

***"EU-weite und umfassende Regulierung für KI"***

- ***"Europas erste umfassende Gesetzgebung zur Regulierung von KI-Systemen nach Risikokategorien"***  (Claude)
- ***"Europas Versuch, KI an die Leine zu nehmen – mal sehen, wer wen führt"***  (ChatGPT)
- ***"Regeln für KI, damit sie nicht die Welt übernimmt"*** (Grok)

Der **AI Act** ist die weltweit erste umfassende Regulierung für Künstliche Intelligenz.
Entwickelt von der Europäischen Union entwickelt, etabliert sie einen risikobasierten Regulierungsansatz für KI-Systeme.

### Entstehung und Zeitrahmen {.explanation}

Der Entwicklungsprozess des AI Acts durchlief mehrere Phasen:

- **April 2021**: Erster Entwurf durch die Europäische Kommission vorgelegt  
- **Dezember 2023**: Vorläufige politische Einigung zwischen Europäischem Parlament und Rat  
- **März 2024**: Formelle Verabschiedung durch das Europäische Parlament  
- **Veröffentlichung und Inkrafttreten**: Nach finaler Zustimmung durch den Rat und Veröffentlichung im EU-Amtsblatt  
- **Umsetzungszeitraum**: Gestaffelte Implementierung über 24 bis 36 Monate nach Inkrafttreten  

### Regulatorischer Ansatz {.explanation}

Der AI Act folgt einem risikobasierten Ansatz, der KI-Systeme je nach ihrem Risikopotenzial in verschiedene Kategorien einteilt:

1. **Unakzeptables Risiko**: Verbotene KI-Anwendungen  
   - Soziale Bewertungssysteme durch Behörden  
   - Biometrische Echtzeit-Fernidentifikation in öffentlichen Räumen (mit begrenzten Ausnahmen)  
   - Emotionserkennungssysteme am Arbeitsplatz und in Bildungseinrichtungen  
   - KI-Systeme zur Manipulation menschlichen Verhaltens  

2. **Hohes Risiko**: Strenge Anforderungen vor Marktzugang  
   - Kritische Infrastruktur (Verkehr, Wasser, Energie)  
   - Bildungs- und Berufsausbildungssysteme  
   - Sicherheitskomponenten von Produkten  
   - Beschäftigung, Personalmanagement und Zugang zur Selbstständigkeit  
   - Zugang zu wesentlichen Diensten (Kredit, Versicherungen)  
   - Strafverfolgung und Justiz  
   - Migration und Grenzkontrollen  

3. **Begrenztes Risiko**: Transparenzpflichten  
   - Kennzeichnungspflicht für KI-generierte Inhalte (Deepfakes)  
   - Offenlegung bei Interaktion mit KI-Systemen  
   - Kennzeichnung von Emotionserkennungssystemen  

4. **Minimales/kein Risiko**: Keine spezifischen Vorgaben  
   - KI-Anwendungen wie Spam-Filter oder Videospiele  

### Spezielle Regelungen für GPAI (General Purpose AI) {.explanation}

Der AI Act enthält besondere Bestimmungen für leistungsstarke, generelle KI-Modelle (GPAI), wozu auch [Foundation Models](#Foundation-Model) und [Large Language Models](#Large-Language-Model) zählen:

- **Transparenzanforderungen**: Dokumentation der Trainingsdaten und Modellarchitektur  
- **Risikobewertung und -minderung**: Identifikation und Adressierung systemischer Risiken  
- **Cybersicherheitsanforderungen**: Schutz vor unautorisierten Zugriffen und Manipulation  
- **Energieeffizienz**: Berichterstattung über Energieverbrauch  
- **Kategorisierung**: Besondere Anforderungen für Hochrisiko-GPAI-Systeme  

Die Anforderungen variieren je nach Größe und Kapazität der Modelle, mit strengeren Regeln für leistungsstärkere Systeme.

### Durchsetzung und Governance {.explanation}

Zur Umsetzung und Überwachung der Verordnung sind verschiedene Mechanismen vorgesehen:

- **European Artificial Intelligence Board**: Beratungsgremium zur Unterstützung einer einheitlichen Anwendung  
- **Nationale Aufsichtsbehörden**: Primäre Durchsetzung auf Mitgliedstaatenebene  
- **Sanktionen**: Gestaffelte Bußgelder bis zu 35 Millionen Euro oder 7 % des weltweiten Jahresumsatzes  
- **Verhaltenskodizes**: Freiwillige Selbstverpflichtungen für nicht hochriskante KI-Systeme  
- **Unterstützung von Innovation**: Regulatorische Sandboxes und Maßnahmen für KMU  

### Internationale Auswirkungen {.explanation}

Der AI Act hat globale Bedeutung über die EU-Grenzen hinaus:

- **Brüssel-Effekt**: Potenzial, de-facto globaler Standard zu werden, ähnlich wie die DSGVO  
- **Internationale Kooperation**: Bemühungen um globale Standards für KI-Governance  
- **Wettbewerbsposition**: Balanceakt zwischen Innovation und Regulierung im globalen KI-Wettlauf  
- **Regulatorische Inspiration**: Einfluss auf KI-Gesetzgebung in anderen Jurisdiktionen  

### Kritik und Diskussionspunkte {.explanation}

Der AI Act wird aus verschiedenen Perspektiven kritisch betrachtet:

- **Innovationshemmung**: Befürchtungen, dass strenge Regulierung die KI-Entwicklung in Europa ausbremst  
- **Durchführbarkeit**: Herausforderungen bei der praktischen Umsetzung komplexer Anforderungen  
- **Offene Definitionen**: Interpretationsspielraum bei zentralen Begriffen wie "hohes Risiko"  
- **Balance**: Abwägung zwischen Schutz und technologischem Fortschritt  
- **Urheberrecht**: Unzureichende Adressierung von Copyright-Fragen bei Trainingsdaten  

### KI-Haikus zu AI Act  {.haiku}

: Haikus zu AI Act

+--------------------------------------+---------------------------------------+--------------------------------------+
| Claude                               | ChatGPT                               | Grok                                 |
+:=====================================+:=====================================:+=====================================:+
| Brüssel schreibt Regeln\             | Europa bremst KI,\                    | Regeln für die KI\                   |
| Algorithmen gezähmt\                 | setzt Regeln, hofft auf Vernunft –\   | Sicherheit vor Machtgewinn\          |
| Digitale Zügel                       | doch bleibt sie gefasst?              | Europa wacht auf                     |
+:=====================================+=======================================+=====================================:+
| ***"Europas Versuch, KI an die Leine zu nehmen – mal sehen, wer wen führt."*** (ChatGPT)                            |
+:===================================================================================================================:+


### Verwandte oder andere interessante Themen: {.seealso}

[AI Ethics](#AI-Ethics) |
[AI Safety](#AI-Safety) |
[Data Sovereignty](#Data-Sovereignty) |
[Foundation Model](#Foundation-Model) |
[KI-Regulierung](#KI-Regulierung) |
[Responsible AI](#Responsible-AI) |
[Index](#Index) |

----


