## GPT-3 {#GPT-3 .chapter .small .term}

**GPT-3 (Generative Pre-trained Transformer 3)** ist ein 2020 veröffentlichtes [Large Language Model](#Large-Language-Model) von [OpenAI](#OpenAI), das mit 175 Milliarden Parametern einen Meilenstein in der Skalierung von KI-Modellen darstellte und den breiten Durchbruch generativer Textmodelle einleitete.

### Technische Architektur {.explanation}

GPT-3 basiert auf der [Transformer](#Transformer)-Architektur und stellte bei seiner Veröffentlichung das größte trainierte Sprachmodell dar.

Die wichtigsten technischen Merkmale umfassen:

- **Skalierung**: 175 Milliarden Parameter, etwa 100-mal mehr als sein Vorgänger GPT-2
- **Training**: Vortraining auf einem umfangreichen Textkorpus von etwa 570 GB, darunter Common Crawl, WebText, Bücher und Wikipedia
- **Decoder-Only**: Architektur mit unidirektionaler Aufmerksamkeit zur Vorhersage der nächsten Token
- **[Attention Mechanism](#Attention-Mechanism)**: Verwendung von selbstaufmerksamkeitsbasierten Berechnungen für kontextbezogene Textverarbeitung
- **[Kontextfenster](#Context-Window)**: Verarbeitung von bis zu 2048 Tokens (etwa 1500 Wörter)

Die enorme Modellgröße führte zu emergenten Fähigkeiten, die in kleineren Modellen nicht beobachtet wurden und die [Skalierungs-Hypothese](#Skalierungs-Hypothese) empirisch unterstützten.

### Fähigkeiten und Anwendungen {.explanation}

GPT-3 zeigte bemerkenswerte Sprachfähigkeiten ohne spezifisches [Fine-Tuning](#Fine-Tuning):

- **[Few-Shot Learning](#Few-Shot-Learning)**: Fähigkeit, Aufgaben mit nur wenigen Beispielen zu lernen
- **[Zero-Shot Learning](#Zero-Shot-Learning)**: Lösen unbekannter Aufgaben ohne vorherige Beispiele
- **Textgenerierung**: Erstellung kohärenter, langer Texte verschiedener Stile und Formate
- **Übersetzung**: Mehrsprachige Konvertierung mit begrenzter Genauigkeit
- **Codegeneration**: Einfache Programmierung basierend auf natürlichsprachlichen Beschreibungen
- **Kreatives Schreiben**: Erstellung von Gedichten, Geschichten und anderen kreativen Inhalten

Diese Fähigkeiten ermöglichten vielfältige Anwendungen in Bereichen wie Content-Erstellung, Kundenservice, Bildung und Programmierung.

### Bereitstellung und Kommerzialisierung {.explanation}

OpenAI verfolgte mit GPT-3 einen neuartigen Kommerzialisierungsansatz:

- **API-Zugang**: Bereitstellung ausschließlich als Cloud-API statt Open-Source-Veröffentlichung
- **Lizenzierung**: Exklusive Lizenzvereinbarung mit Microsoft für bestimmte Anwendungsbereiche
- **Sicherheitsmaßnahmen**: Schrittweise Erweiterung des Zugangs zur Überwachung von Missbrauchsmöglichkeiten
- **Produktökosystem**: Ermöglichung zahlreicher Startups und Anwendungen auf Basis der GPT-3-API

Dieser Ansatz markierte eine Abkehr von OpenAIs ursprünglicher Open-Source-Philosophie und setzte einen Präzedenzfall für spätere [Foundation Models](#Foundation-Model).

### Historische Bedeutung {.explanation}

GPT-3 hatte weitreichende Auswirkungen auf die KI-Landschaft:

- **Paradigmenwechsel**: Verlagerung vom spezialisierten Training hin zu großen, vielseitigen Basismodellen
- **Industrielle Transformation**: Beschleunigung der KI-Kommerzialisierung und Investitionen
- **Ethische Debatten**: Intensivierung von Diskussionen über [AI Ethics](#AI-Ethics), [Fairness](#Fairness) und [Bias](#Bias)
- **Forschungsrichtung**: Bestätigung der Skalierungsstrategie als dominanter Ansatz in der KI-Forschung
- **Gesellschaftliches Bewusstsein**: Breitere öffentliche Wahrnehmung des Potenzials und der Risiken fortschrittlicher KI

Als direkter Vorgänger von Modellen wie [ChatGPT](#ChatGPT) legte GPT-3 den Grundstein für die heutige Verbreitung generativer KI-Systeme und die daraus resultierende technologische und gesellschaftliche Transformation.

### Verwandte oder andere interessante Themen: {.seealso}

[Foundation Model](#Foundation-Model) |
[Generative Pre-Trained Transformer](#Generative-Pre-Trained-Transformer) |
[GPT-3.5](#GPT-3.5) |
[GPT-4](#GPT-4) |
[Natural Language Generation](#Natural-Language-Generation) |
[OpenAI](#OpenAI) |
[Transformer](#Transformer) |
[Index](#Index) |

----


