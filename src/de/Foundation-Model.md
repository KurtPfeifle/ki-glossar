## Foundation Model {#Foundation-Model .chapter .small .term}

**Foundation Models** sind große, auf umfangreichen Datensätzen vortrainierte KI-Modelle, die als Grundlage für verschiedene nachgelagerte Anwendungen durch [Fine-Tuning](#Fine-Tuning) oder [Prompting](#Prompting) dienen.

### Kernkonzept {.explanation}

Foundation Models zeichnen sich durch ihre enorme Parameteranzahl und die breite Wissensbasis aus, die sie während des Pre-Trainings auf diversen Datenquellen erwerben.
Sie repräsentieren einen Paradigmenwechsel in der KI-Entwicklung, bei dem ein einzelnes Basismodell für zahlreiche unterschiedliche Aufgaben adaptiert werden kann.

Charakteristische Eigenschaften von Foundation Models sind:

- **Emergente Fähigkeiten**: Entwicklung von Fähigkeiten, die nicht explizit trainiert wurden
- **Skalierbarkeit**: Leistungssteigerung durch Vergrößerung von Modell und Datenmenge
- **Transferfähigkeit**: Anwendbarkeit auf verschiedene Domänen und Aufgaben
- **Kontextverständnis**: Fähigkeit, aufgabenspezifische Anweisungen zu interpretieren
- **Multimodale Integration**: Zunehmend Verarbeitung verschiedener Datentypen (Text, Bild, Audio)

### Architekturtypen {.explanation}

Foundation Models lassen sich in verschiedene Kategorien einteilen:

- **Large Language Models (LLMs)**: Textbasierte Modelle wie GPT-4, Claude oder Llama
- **Multimodale Modelle**: Verarbeiten mehrere Datentypen, wie GPT-4V oder Gemini
- **Diffusionsmodelle**: Generative Bildmodelle wie Stable Diffusion oder DALL-E
- **Audio-/Videomodelle**: Spezialisierte Modelle für audiovisuelle Daten, wie Whisper oder Sora

Foundation Models haben die KI-Landschaft signifikant verändert, indem sie die Entwicklung spezialisierter Anwendungen demokratisiert haben.
Organisationen können nun fortschrittliche KI-Lösungen implementieren, ohne vollständige Modelle von Grund auf trainieren zu müssen.

### Verwandte Themen {.seealso}

[Emergent Abilities](#Emergent-Abilities) |
[Fine-Tuning](#Fine-Tuning) |
[Frontier Models](#Frontier-Models) |
[Large Language Model](#Large-Language-Model) |
[Pre-Training](#Pre-Training) |
[Prompt Engineering](#Prompt-Engineering) |
[Scaling Law](#Scaling-Law) |
[Transfer Learning](#Transfer-Learning) |
[Index](#Index) |

----

