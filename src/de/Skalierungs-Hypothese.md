## Skalierungs-Hypothese {#Skalierungs-Hypothese .chapter .small .term}

Die **Skalierungs-Hypothese** besagt, dass KI-Modelle kontinuierlich leistungsfähiger werden, wenn drei Faktoren erhöht werden: Modellgröße (Parameter), Datenmenge und Rechenleistung.

### Kernkonzept {.explanation}

Die Skalierungs-Hypothese beschreibt einen fundamentalen Zusammenhang in der KI-Entwicklung, der durch empirische Beobachtungen gestützt wird.
Sie postuliert, dass signifikante Leistungssteigerungen und neue Fähigkeiten primär durch Skalierung erreicht werden können, ohne dass grundlegende architektonische Veränderungen notwendig sind.

Die drei zentralen Skalierungsdimensionen umfassen:

- **[Parameterzahl](#Parameter-Count)**: Erhöhung der Modellkapazität durch mehr trainierbare Parameter
- **Datenmenge**: Erweiterung des Trainingskorpus in Umfang und Diversität
- **Rechenleistung**: Steigerung der für das Training verfügbaren [Compute](#Compute)-Ressourcen

Diese Perspektive wurde maßgeblich durch die Arbeit von [OpenAI](#OpenAI)-Forschern geprägt, insbesondere durch Kaplan et al. (2020) mit dem Artikel "Scaling Laws for Neural Language Models".

### Bedeutung und Kontroversen {.explanation}

Die Skalierungs-Hypothese hat weitreichende Implikationen für die KI-Forschung und -Industrie:

- **Investitionsstrategien**: Fokus auf Infrastruktur und Datenakquisition statt algorithmischer Innovation
- **Ressourcenzentralisierung**: Begünstigung großer Technologieunternehmen mit umfangreichen Ressourcen
- **Emergente Fähigkeiten**: Vorhersage qualitativer Sprünge durch quantitative Skalierung
- **Effizienzforschung**: Gegenbewegung zur Entwicklung ressourcenschonender Modellarchitekturen

Kritiker argumentieren, dass reine Skalierung Grenzen hat und dass architektonische Innovationen, bessere Datenqualität und neuartige Trainingsmethoden ebenso wichtig sind.
Die Debatte zwischen *"Scaling-ist-alles"* und *"Qualität-vor-Quantität"* bleibt ein zentrales Spannungsfeld in der KI-Forschungscommunity.

### Verwandte Themen {.seealso}

[Compute Budget](#Compute-Budget) |
[Efficient Frontier](#Efficient-Frontier) |
[Emergent Abilities](#Emergent-Abilities) |
[Foundation Model](#Foundation-Model) |
[Green AI](#Green-AI) |
[Parameter Count](#Parameter-Count) |
[Scaling Law](#Scaling-Law) |
[Training Data](#Training-Data) |
[Index](#Index) |

----


